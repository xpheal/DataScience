{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Report\n",
    "## Files\n",
    "setC.csv = data obtained from the blocking stage  \n",
    "sampleA.csv = 800 rows that are sample with (seed = 10) from setC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "setC = None\n",
    "with open('labelled.csv', 'r') as file:\n",
    "    setA = list(csv.reader(file))\n",
    "    setA = setA[1:] # Remove header\n",
    "    setB = setA[350:] # Evaluation set\n",
    "    setA = setA[:350] # Development set\n",
    "\n",
    "class attr:\n",
    "    label = 0\n",
    "    _id = 1\n",
    "    ltable_Id = 2\n",
    "    rtable_Id = 3\n",
    "    ltable_Title = 4\n",
    "    ltable_Category = 5\n",
    "    ltable_Duration = 6\n",
    "    ltable_Rating = 7\n",
    "    ltable_Rating_Count = 8\n",
    "    ltable_Director = 9 \n",
    "    rtable_Title = 10\n",
    "    rtable_Category = 11\n",
    "    rtable_Duration = 12\n",
    "    rtable_Rating = 13\n",
    "    rtable_Rating_Count = 14\n",
    "    rtable_Director = 15\n",
    "    strings = ['label', '_id', 'ltable_Id', 'rtable_Id', 'ltable_Title', 'ltable_Category', \n",
    "               'ltable_Duration', 'ltable_Rating', 'ltable_Rating_Count', 'ltable_Director', \n",
    "               'rtable_Title', 'rtable_Category', 'rtable_Duration', 'rtable_Rating', 'rtable_Rating_Count',\n",
    "               'rtable_Director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate number of null value for each attributes\n",
    "def check_null(setx):\n",
    "    num_null = [0 for i in range(16)]\n",
    "    \n",
    "    for row in setx:\n",
    "        for pos, val in enumerate(row):\n",
    "            if not val:\n",
    "                num_null[pos] += 1\n",
    "    \n",
    "    for pos, val in enumerate(num_null):\n",
    "        print(attr.strings[pos] + \": \" + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that scan the whole table and remove null value based on pos\n",
    "def fill_null(setx, pos, val):\n",
    "    for row in setx:\n",
    "        if not row[pos]:\n",
    "            row[pos] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Values with null item, size of setA = 800\n",
    "# print(\"SetA\")\n",
    "# check_null(setA)\n",
    "fill_null(setA, attr.ltable_Rating, 0)\n",
    "fill_null(setA, attr.rtable_Rating, 0)\n",
    "fill_null(setA, attr.ltable_Duration, 0)\n",
    "fill_null(setA, attr.rtable_Duration, 0)\n",
    "fill_null(setA, attr.ltable_Rating_Count, 0)\n",
    "fill_null(setA, attr.rtable_Rating_Count, 0)\n",
    "# print(\"SetB\")\n",
    "# check_null(setB)\n",
    "fill_null(setB, attr.ltable_Rating, 0)\n",
    "fill_null(setB, attr.rtable_Rating, 0)\n",
    "fill_null(setB, attr.ltable_Duration, 0)\n",
    "fill_null(setB, attr.rtable_Duration, 0)\n",
    "fill_null(setB, attr.ltable_Rating_Count, 0)\n",
    "fill_null(setB, attr.rtable_Rating_Count, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Matching\n",
    "Start by converting each labelled row into a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble, linear_model, svm, naive_bayes\n",
    "from sklearn.model_selection import KFold\n",
    "from py_stringmatching.tokenizer.delimiter_tokenizer import DelimiterTokenizer\n",
    "from py_stringmatching.similarity_measure.levenshtein import Levenshtein\n",
    "\n",
    "delim_tkn = DelimiterTokenizer()\n",
    "lev = Levenshtein()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def title_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def category_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "    \n",
    "def rating_match(x, y):\n",
    "    return abs(float(x) - float(y))\n",
    "    \n",
    "def director_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def rating_count_match(x, y):\n",
    "    return abs(float(x) - float(y))\n",
    "\n",
    "def duration_match(x, y):\n",
    "    return abs(float(x) - float(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a set, return the feature vectors and label\n",
    "def get_feature(setx):\n",
    "    feature = []\n",
    "    label = []\n",
    "    \n",
    "    for row in setx:\n",
    "        label += [row[attr.label]]\n",
    "        \n",
    "        x_0 = title_match(row[attr.ltable_Title], row[attr.rtable_Title])\n",
    "        x_1 = category_match(row[attr.ltable_Category], row[attr.rtable_Category])\n",
    "        x_2 = rating_match(row[attr.ltable_Rating], row[attr.rtable_Rating])\n",
    "        x_3 = director_match(row[attr.ltable_Director], row[attr.rtable_Director])\n",
    "        x_4 = duration_match(row[attr.ltable_Duration], row[attr.rtable_Duration])\n",
    "        x_5 = rating_count_match(row[attr.ltable_Rating_Count], row[attr.rtable_Rating_Count])\n",
    "        \n",
    "        feature += [[x_0, x_1, x_2, x_3]]\n",
    "        \n",
    "    return feature, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ltable(setx):\n",
    "    return [[row[attr.ltable_Id]] + row[attr.ltable_Title:attr.ltable_Director + 1]for row in setx]\n",
    "\n",
    "def get_rtable(setx):\n",
    "    return [[row[attr.rtable_Id]] + row[attr.rtable_Title:]for row in setx]\n",
    "\n",
    "def get_label(setx):\n",
    "    return [row[attr.label] for row in setx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a list of real result and predicted result, calculate precision, recall and F1\n",
    "def get_F1(real, predicted):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for pos,res in enumerate(predicted):\n",
    "        if res == real[pos]:\n",
    "            if res == '1':\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "        else:\n",
    "            if res == '1':\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "    \n",
    "    # If true_positive, false_positive or false_negative causes zero error: set precision, recall and F1 to zero\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return 0,0,0\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug(ltable, rtable, label, predicted):\n",
    "    for pos,res in enumerate(predicted):\n",
    "        if res != label[pos]:\n",
    "            print(\"ltable: \" + str(ltable[pos]))\n",
    "            print(\"rtable: \" + str(rtable[pos]))\n",
    "            print(\"Label: \" + str(label[pos]) + \" Predicted: \" + str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test setx using the classifier = clf\n",
    "def clf_test(setx, clf, test_name='TEST', verbose=False, get_feature=get_feature):\n",
    "    feature, label = get_feature(setx)\n",
    "    result = clf.predict(feature)\n",
    "    precision, recall, F1 = get_F1(label, result)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(test_name.upper())\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"F1: \" + str(F1))\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and test on setx using the classifier = clf and k-fold validation = k\n",
    "# Return the average (precision, recall, F1)\n",
    "def clf_train(setx, clf, k, name='CLASSIFIER', verbose=False, get_feature=get_feature):\n",
    "    # Decision Tree Classifier using k-Fold = 4\n",
    "    split = 4\n",
    "    k_fold = KFold(n_splits=split)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_F1 = 0\n",
    "    \n",
    "    for train, test in k_fold.split(setx):\n",
    "        train = setx[train[0]:train[-1] + 1]\n",
    "        test = setx[test[0]:test[-1] + 1]\n",
    "\n",
    "        feature, label = get_feature(train)\n",
    "        clf = clf.fit(feature, label)\n",
    "        \n",
    "        precision, recall, F1 = clf_test(test, clf, get_feature=get_feature)\n",
    "\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_F1 += F1\n",
    "        \n",
    "    precision = total_precision/split\n",
    "    recall = total_recall/split\n",
    "    F1 = total_F1/split\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(name.upper())\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"F1: \" + str(F1))\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION TREE CLASSIFIER\n",
      "Precision: 0.9388888888888889\n",
      "Recall: 0.9907407407407407\n",
      "F1: 0.9633642930856554\n",
      "\n",
      "EVALUATION ON DECISION TREE CLASSIFIER\n",
      "Precision: 0.7592592592592593\n",
      "Recall: 0.9318181818181818\n",
      "F1: 0.836734693877551\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier using k-Fold = 4\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"decision tree classifier\", verbose=True, get_feature=get_feature)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on decision tree classifier\", verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.9443707633362806\n",
      "Recall: 0.9150841750841752\n",
      "F1: 0.926575682382134\n",
      "\n",
      "EVALUATION ON LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.9090909090909091\n",
      "Recall: 0.9090909090909091\n",
      "F1: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier using k-Fold = 4\n",
    "clf = linear_model.LogisticRegression()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"logistic regression classifier\", verbose=True, get_feature=get_feature)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on logistic regression classifier\", verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.9613095238095237\n",
      "Recall: 0.9547558922558922\n",
      "F1: 0.957717803030303\n",
      "\n",
      "EVALUATION ON RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.9130434782608695\n",
      "Recall: 0.9545454545454546\n",
      "F1: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier using k-Fold = 4\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"random forest classifier\", verbose=True, get_feature=get_feature)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on random forest classifier\", verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUPPORT VECTOR MACHINE CLASSIFIER\n",
      "Precision: 1.0\n",
      "Recall: 0.8055555555555556\n",
      "F1: 0.8785714285714286\n",
      "\n",
      "EVALUATION ON SUPPORT VECTOR MACHINE CLASSIFIER\n",
      "Precision: 1.0\n",
      "Recall: 0.5681818181818182\n",
      "F1: 0.7246376811594203\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classifier using k-Fold = 4\n",
    "clf = svm.SVC()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"support vector machine classifier\", verbose=True, get_feature=get_feature)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on support vector machine classifier\", verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.8969887176227554\n",
      "Recall: 0.9150841750841752\n",
      "F1: 0.9015801886792452\n",
      "\n",
      "EVALUATION ON NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.8163265306122449\n",
      "Recall: 0.9090909090909091\n",
      "F1: 0.8602150537634408\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier using k-Fold = 4\n",
    "clf = naive_bayes.GaussianNB()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"naive bayes classifier\", verbose=True, get_feature=get_feature)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on naive bayes classifier\", verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Classifier\n",
    "Most classfiers return an F1-Score of 0.9 and above, the accuracy is consider high. When tested on the isolated evaluation set, the F1-Score is around 0.9 too. But, we will try to make the classifier even better.  \n",
    "\n",
    "Some things that we plan to look into are:  \n",
    "1) Conversion of data into feature vectors  \n",
    "2) Classifier that is used, we might be able to tweak the scikit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Made\n",
    "Added two new feature vectors:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_match2(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def category_match2(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "    \n",
    "def rating_match2(x, y):\n",
    "    return math.sqrt(abs(float(x) - float(y)))\n",
    "    \n",
    "def director_match2(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def rating_count_match2(x, y):\n",
    "    return math.sqrt(abs(float(x) - float(y)))\n",
    "\n",
    "def duration_match2(x, y):\n",
    "    return math.sqrt(abs(float(x) - float(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a set, return the feature vectors and label\n",
    "def get_feature2(setx):\n",
    "    feature = []\n",
    "    label = []\n",
    "    \n",
    "    for row in setx:\n",
    "        label += [row[attr.label]]\n",
    "        \n",
    "        x_0 = title_match2(row[attr.ltable_Title], row[attr.rtable_Title])\n",
    "        x_1 = category_match2(row[attr.ltable_Category], row[attr.rtable_Category])\n",
    "        x_2 = rating_match2(row[attr.ltable_Rating], row[attr.rtable_Rating])\n",
    "        x_3 = director_match2(row[attr.ltable_Director], row[attr.rtable_Director])\n",
    "        x_4 = duration_match2(row[attr.ltable_Duration], row[attr.rtable_Duration])\n",
    "        x_5 = rating_count_match2(row[attr.ltable_Rating_Count], row[attr.rtable_Rating_Count])\n",
    "        \n",
    "        feature += [[x_0, x_1, x_2, x_3, x_4, x_5]]\n",
    "        \n",
    "    return feature, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from numpy import linspace as lins\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5cea6f9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = lins(0,200)\n",
    "y = list(map(lambda x:math.sqrt(x), x))\n",
    "plot.plot(x,y)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION TREE CLASSIFIER\n",
      "Precision: 0.9532967032967032\n",
      "Recall: 0.9803240740740741\n",
      "F1: 0.9663636363636363\n",
      "\n",
      "EVALUATION ON DECISION TREE CLASSIFIER\n",
      "Precision: 0.8936170212765957\n",
      "Recall: 0.9545454545454546\n",
      "F1: 0.9230769230769231\n",
      "\n",
      "LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.9222222222222223\n",
      "Recall: 0.9504377104377104\n",
      "F1: 0.9321454396013129\n",
      "\n",
      "EVALUATION ON LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.8723404255319149\n",
      "Recall: 0.9318181818181818\n",
      "F1: 0.9010989010989012\n",
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.9715099715099715\n",
      "Recall: 0.9907407407407407\n",
      "F1: 0.9807407407407407\n",
      "\n",
      "EVALUATION ON RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.9318181818181818\n",
      "Recall: 0.9318181818181818\n",
      "F1: 0.9318181818181818\n",
      "\n",
      "SUPPORT VECTOR MACHINE CLASSIFIER\n",
      "Precision: 0.75\n",
      "Recall: 0.5104166666666667\n",
      "F1: 0.52\n",
      "\n",
      "EVALUATION ON SUPPORT VECTOR MACHINE CLASSIFIER\n",
      "Precision: 1.0\n",
      "Recall: 0.022727272727272728\n",
      "F1: 0.044444444444444446\n",
      "\n",
      "NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.93\n",
      "Recall: 0.9236026936026936\n",
      "F1: 0.922115034328149\n",
      "\n",
      "EVALUATION ON NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.8666666666666667\n",
      "Recall: 0.8863636363636364\n",
      "F1: 0.8764044943820225\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier using k-Fold = 4\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"decision tree classifier\", verbose=True, get_feature=get_feature2)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on decision tree classifier\", verbose=True, get_feature=get_feature2)\n",
    "# Logistic Regression Classifier using k-Fold = 4\n",
    "clf = linear_model.LogisticRegression()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"logistic regression classifier\", verbose=True, get_feature=get_feature2)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on logistic regression classifier\", verbose=True, get_feature=get_feature2)\n",
    "# Random Forest Classifier using k-Fold = 4\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"random forest classifier\", verbose=True, get_feature=get_feature2)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on random forest classifier\", verbose=True, get_feature=get_feature2)\n",
    "# Support Vector Machine Classifier using k-Fold = 4\n",
    "clf = svm.SVC()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"support vector machine classifier\", verbose=True, get_feature=get_feature2)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on support vector machine classifier\", verbose=True, get_feature=get_feature2)\n",
    "# Naive Bayes Classifier using k-Fold = 4\n",
    "clf = naive_bayes.GaussianNB()\n",
    "precision, recall, F1 = clf_train(setA, clf, 4, \"naive bayes classifier\", verbose=True, get_feature=get_feature2)\n",
    "precision_b, recall_b, F1_b = clf_test(setB, clf, \"evaluation on naive bayes classifier\", verbose=True, get_feature=get_feature2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
