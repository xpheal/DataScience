{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Report\n",
    "## Files\n",
    "setC.csv = data obtained from the blocking stage  \n",
    "sampleA.csv = 800 rows that are sample with (seed = 10) from setC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "setC = None\n",
    "with open('labelled_year.csv', 'r') as file:\n",
    "    setA = list(csv.reader(file))\n",
    "    setA = setA[1:] # Remove header\n",
    "    setB = setA[375:] # Evaluation set\n",
    "    setA = setA[:375] # Development set\n",
    "\n",
    "class attr:\n",
    "    label = 0\n",
    "    _id = 1\n",
    "    ltable_Id = 2\n",
    "    rtable_Id = 3\n",
    "    ltable_Title = 4\n",
    "    ltable_Category = 5\n",
    "    ltable_Duration = 6\n",
    "    ltable_Rating = 7\n",
    "    ltable_Rating_Count = 8\n",
    "    ltable_Director = 9 \n",
    "    ltable_Year = 10\n",
    "    rtable_Title = 11\n",
    "    rtable_Category = 12\n",
    "    rtable_Duration = 13\n",
    "    rtable_Rating = 14\n",
    "    rtable_Rating_Count = 15\n",
    "    rtable_Director = 16\n",
    "    rtable_Year = 17\n",
    "    strings = ['label', '_id', 'ltable_Id', 'rtable_Id', 'ltable_Title', 'ltable_Category', \n",
    "               'ltable_Duration', 'ltable_Rating', 'ltable_Rating_Count', 'ltable_Director', \n",
    "               'ltable_Year', 'rtable_Title', 'rtable_Category', 'rtable_Duration', 'rtable_Rating',\n",
    "               'rtable_Rating_Count', 'rtable_Director', 'rtable_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate number of null value for each attributes\n",
    "def check_null(setx):\n",
    "    num_null = [0 for i in range(16)]\n",
    "    \n",
    "    for row in setx:\n",
    "        for pos, val in enumerate(row):\n",
    "            if not val:\n",
    "                num_null[pos] += 1\n",
    "    \n",
    "    for pos, val in enumerate(num_null):\n",
    "        print(attr.strings[pos] + \": \" + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that scan the whole table and remove null value based on pos\n",
    "def fill_null(setx, pos, val):\n",
    "    for row in setx:\n",
    "        if not row[pos]:\n",
    "            row[pos] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Values with null item, size of setA = 800\n",
    "# print(\"SetA\")\n",
    "# check_null(setA)\n",
    "fill_null(setA, attr.ltable_Rating, 50)\n",
    "fill_null(setA, attr.rtable_Rating, 50)\n",
    "fill_null(setA, attr.ltable_Duration, 0)\n",
    "fill_null(setA, attr.rtable_Duration, 0)\n",
    "fill_null(setA, attr.ltable_Rating_Count, 0)\n",
    "fill_null(setA, attr.rtable_Rating_Count, 0)\n",
    "fill_null(setA, attr.ltable_Year, 0)\n",
    "fill_null(setA, attr.rtable_Year, 0)\n",
    "# print(\"SetB\")\n",
    "# check_null(setB)\n",
    "fill_null(setB, attr.ltable_Rating, 50)\n",
    "fill_null(setB, attr.rtable_Rating, 50)\n",
    "fill_null(setB, attr.ltable_Duration, 0)\n",
    "fill_null(setB, attr.rtable_Duration, 0)\n",
    "fill_null(setB, attr.ltable_Rating_Count, 0)\n",
    "fill_null(setB, attr.rtable_Rating_Count, 0)\n",
    "fill_null(setB, attr.ltable_Year, 0)\n",
    "fill_null(setB, attr.rtable_Year, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Matching\n",
    "Start by converting each labelled row into a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble, linear_model, svm, naive_bayes\n",
    "from sklearn.model_selection import KFold\n",
    "from py_stringmatching.tokenizer.delimiter_tokenizer import DelimiterTokenizer\n",
    "from py_stringmatching.similarity_measure.levenshtein import Levenshtein\n",
    "\n",
    "delim_tkn = DelimiterTokenizer()\n",
    "lev = Levenshtein()\n",
    "\n",
    "class_group = ['d', 'l', 'r', 's', 'n']\n",
    "classifiers = {'d':tree.DecisionTreeClassifier(), 'l':linear_model.LogisticRegression(), 'r':ensemble.RandomForestClassifier(), 's':svm.SVC(), 'n':naive_bayes.GaussianNB()}\n",
    "names = {'d':'DECISION TREE', 'l':'LOGISTIC REGRESSION', 'r':'RANDOM FOREST', 's':'SUPPORT VECTOR MACHING', 'n':'NAIVE BAYES'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def title_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def category_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "    \n",
    "def rating_match(x, y):\n",
    "    return abs(float(x) - float(y))\n",
    "    \n",
    "def director_match(x, y):\n",
    "    return lev.get_raw_score(x, y)\n",
    "\n",
    "def rating_count_match(x, y):\n",
    "    return abs(float(x) - float(y))\n",
    "\n",
    "def duration_match(x, y):\n",
    "    return abs(float(x) - float(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a set, return the feature vectors and label\n",
    "def get_feature(setx):\n",
    "    feature = []\n",
    "    label = []\n",
    "    \n",
    "    for row in setx:\n",
    "        label += [row[attr.label]]\n",
    "        \n",
    "        x_0 = title_match(row[attr.ltable_Title], row[attr.rtable_Title])\n",
    "        x_1 = category_match(row[attr.ltable_Category], row[attr.rtable_Category])\n",
    "        x_2 = rating_match(row[attr.ltable_Rating], row[attr.rtable_Rating])\n",
    "        x_3 = director_match(row[attr.ltable_Director], row[attr.rtable_Director])\n",
    "        x_4 = duration_match(row[attr.ltable_Duration], row[attr.rtable_Duration])\n",
    "        x_5 = rating_count_match(row[attr.ltable_Rating_Count], row[attr.rtable_Rating_Count])\n",
    "        \n",
    "        feature += [[x_0, x_1, x_2, x_3]]\n",
    "        \n",
    "    return feature, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ltable(setx):\n",
    "    return [[row[attr.ltable_Id]] + row[attr.ltable_Title:attr.ltable_Year + 1]for row in setx]\n",
    "\n",
    "def get_rtable(setx):\n",
    "    return [[row[attr.rtable_Id]] + row[attr.rtable_Title:]for row in setx]\n",
    "\n",
    "def get_label(setx):\n",
    "    return [row[attr.label] for row in setx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a list of real result and predicted result, calculate precision, recall and F1\n",
    "def get_F1(real, predicted):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for pos,res in enumerate(predicted):\n",
    "        if res == real[pos]:\n",
    "            if res == '1':\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "        else:\n",
    "            if res == '1':\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "    \n",
    "    # If true_positive, false_positive or false_negative causes zero error: set precision, recall and F1 to zero\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return 0,0,0\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug_x(ltable, rtable, label, predicted):\n",
    "    for pos,res in enumerate(predicted):\n",
    "        if res != label[pos]:\n",
    "            print(\"ltable: \" + str(ltable[pos]))\n",
    "            print(\"rtable: \" + str(rtable[pos]))\n",
    "            print(\"Label: \" + str(label[pos]) + \" Predicted: \" + str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test setx using the classifier = clf\n",
    "def clf_test(setx, clf, test_name='TEST', verbose=False, get_feature=get_feature, debug=False):\n",
    "    feature, label = get_feature(setx)\n",
    "    result = clf.predict(feature)\n",
    "    precision, recall, F1 = get_F1(label, result)\n",
    "    \n",
    "    if debug:\n",
    "        debug_x(get_ltable(setx), get_rtable(setx), label, result)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(test_name.upper())\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"F1: \" + str(F1))\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and test on setx using the classifier = clf and k-fold validation = k\n",
    "# Return the average (precision, recall, F1)\n",
    "# clf : 'd' = DecisionTree, 'l' = Logistic Regression, 'r' = Random Forest, 's' = Support Vector Machine, 'n' = Naive Bayes\n",
    "def clf_train(setx, clf, k, verbose=False, get_feature=get_feature, debug=False):\n",
    "    if not clf in class_group:\n",
    "        print(\"ERROR: clf must be either = 'd', 'l', 'r', 's', 'n'\")\n",
    "        return\n",
    "        \n",
    "    # Decision Tree Classifier using k-Fold = 4\n",
    "    split = 4\n",
    "    k_fold = KFold(n_splits=split)\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_F1 = 0\n",
    "    \n",
    "    for train, test in k_fold.split(setx):\n",
    "        train = setx[train[0]:train[-1] + 1]\n",
    "        test = setx[test[0]:test[-1] + 1]\n",
    "        feature, label = get_feature(train)\n",
    "        \n",
    "        clf_x = classifiers[clf]        \n",
    "        clf_x = clf_x.fit(feature, label)\n",
    "        \n",
    "        precision, recall, F1 = clf_test(test, clf_x, get_feature=get_feature, debug=debug)\n",
    "\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_F1 += F1\n",
    "        \n",
    "    precision = total_precision/split\n",
    "    recall = total_recall/split\n",
    "    F1 = total_F1/split\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(names[clf] + \" CLASSIFIER\")\n",
    "        print(\"Precision: \" + str(precision))\n",
    "        print(\"Recall: \" + str(recall))\n",
    "        print(\"F1: \" + str(F1))\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION TREE CLASSIFIER\n",
      "Precision: 0.9365384615384615\n",
      "Recall: 0.9857142857142858\n",
      "F1: 0.959815078236131\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 'd', 4, verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.9417755991285404\n",
      "Recall: 0.9491596638655462\n",
      "F1: 0.9434857786187878\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 'l', 4, verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.96760710553814\n",
      "Recall: 0.9640756302521009\n",
      "F1: 0.9652812617584346\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 'r', 4, verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUPPORT VECTOR MACHING CLASSIFIER\n",
      "Precision: 1.0\n",
      "Recall: 0.8216931216931217\n",
      "F1: 0.8914576802507836\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classifier using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 's', 4, verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.9257859169653525\n",
      "Recall: 0.9130252100840336\n",
      "F1: 0.9153675981349348\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 'n', 4, verbose=True, get_feature=get_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Classifier\n",
    "Most classfiers return an F1-Score of 0.9 and above, the accuracy is consider high. When tested on the isolated evaluation set, the F1-Score is around 0.9 too. But, we will try to make the classifier even better.  \n",
    "\n",
    "Some things that we plan to look into are:  \n",
    "1) Conversion of data into feature vectors  \n",
    "2) Classifier that is used, we might be able to tweak the scikit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Made\n",
    "Added two new feature vectors:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_match2(x, y):\n",
    "    return lev.get_sim_score(x.lower(), y.lower())\n",
    "\n",
    "def category_match2(x, y):\n",
    "    cat_x = x.split(',')\n",
    "    cat_y = y.split(',')\n",
    "    \n",
    "    count = 0\n",
    "    for i in cat_x:\n",
    "        for j in cat_y:\n",
    "            if i == j:\n",
    "                count += 1\n",
    "    return count\n",
    "    \n",
    "def rating_match2(x, y):\n",
    "    return math.sqrt(abs(float(x) - float(y)))\n",
    "    \n",
    "def director_match2(x, y):\n",
    "    dir_x = x.split(',')\n",
    "    dir_y = x.split(',')\n",
    "    \n",
    "    count = 0\n",
    "    for i in dir_x:\n",
    "        for j in dir_y:\n",
    "            ii = i.strip().lower()\n",
    "            jj = j.strip().lower()\n",
    "            if ii and jj:\n",
    "                if lev.get_sim_score(ii,jj) > 0.9:\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "def rating_count_match2(x, y):\n",
    "    return math.sqrt(math.sqrt(abs(float(x) - float(y))))\n",
    "\n",
    "def duration_match2(x, y):\n",
    "    return math.sqrt(math.sqrt(abs(float(x) - float(y))))\n",
    "    \n",
    "def year_match2(x, y):\n",
    "    if x == y:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a set, return the feature vectors and label\n",
    "def get_feature2(setx):\n",
    "    feature = []\n",
    "    label = []\n",
    "    \n",
    "    for row in setx:\n",
    "        label += [row[attr.label]]\n",
    "        \n",
    "        x_0 = title_match2(row[attr.ltable_Title], row[attr.rtable_Title])\n",
    "        x_1 = category_match2(row[attr.ltable_Category], row[attr.rtable_Category])\n",
    "        x_2 = rating_match2(row[attr.ltable_Rating], row[attr.rtable_Rating])\n",
    "        x_3 = director_match2(row[attr.ltable_Director], row[attr.rtable_Director])\n",
    "        x_4 = duration_match2(row[attr.ltable_Duration], row[attr.rtable_Duration])\n",
    "        x_5 = rating_count_match2(row[attr.ltable_Rating_Count], row[attr.rtable_Rating_Count])\n",
    "        x_6 = year_match2(row[attr.ltable_Year], row[attr.rtable_Year])\n",
    "        \n",
    "        feature += [[x_0, x_1, x_2, x_3, x_4, x_5, x_6]]\n",
    "        \n",
    "    return feature, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from numpy import linspace as lins\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION TREE CLASSIFIER\n",
      "Precision: 0.951231527093596\n",
      "Recall: 0.9671957671957672\n",
      "F1: 0.9589285714285714\n",
      "\n",
      "LOGISTIC REGRESSION CLASSIFIER\n",
      "Precision: 0.9752331002331003\n",
      "Recall: 0.9108512293806411\n",
      "F1: 0.9416241583676814\n",
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "Precision: 0.9678571428571429\n",
      "Recall: 0.9928571428571429\n",
      "F1: 0.9796992481203008\n",
      "\n",
      "SUPPORT VECTOR MACHING CLASSIFIER\n",
      "Precision: 0.9290950226244343\n",
      "Recall: 0.8996856520385932\n",
      "F1: 0.9140430556591345\n",
      "\n",
      "NAIVE BAYES CLASSIFIER\n",
      "Precision: 0.9571696052426276\n",
      "Recall: 0.9617491441020853\n",
      "F1: 0.9587955735653946\n"
     ]
    }
   ],
   "source": [
    "# Debug Classifiers using k-Fold = 4\n",
    "precision, recall, F1 = clf_train(setA, 'd', 4, verbose=True, get_feature=get_feature2, debug=False)\n",
    "precision, recall, F1 = clf_train(setA, 'l', 4, verbose=True, get_feature=get_feature2, debug=False)\n",
    "precision, recall, F1 = clf_train(setA, 'r', 4, verbose=True, get_feature=get_feature2, debug=False)\n",
    "precision, recall, F1 = clf_train(setA, 's', 4, verbose=True, get_feature=get_feature2, debug=False)\n",
    "precision, recall, F1 = clf_train(setA, 'n', 4, verbose=True, get_feature=get_feature2, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest weights\n",
      "[ 0.41472247  0.06090439  0.07676553  0.02401065  0.17117527  0.00632803\n",
      "  0.24609366]\n",
      "ltable: ['16751', 'Death Al Dente: A Gourmet Detective Mystery', 'Crime,Drama,Mystery', '0', '67', '63', 'Terry Ingram', '2016']\n",
      "rtable: ['18707', 'Death al Dente: A Gourmet Detective Mystery', 'Mystery', '120', 50, '0', 'Terry Ingram,', '2016']\n",
      "Label: 1 Predicted: 0\n",
      "ltable: ['3703', 'Persuasion', 'Drama,Romance', '93', '76', '10381', 'Adrian Shergold', '2008']\n",
      "rtable: ['13876', 'Persuasion', 'Drama,Romance', '102', '78', '22801', 'Roger Michell,', '1995']\n",
      "Label: 0 Predicted: 1\n",
      "ltable: ['21448', 'Megamind', 'Animation,Television', '0', 50, 0, '', '2010']\n",
      "rtable: ['4077', 'Megamind', 'Action,Adventure,Animation,Comedy,Kids,Family', '96', '76', '207608', 'Tom McGrath,', '2010']\n",
      "Label: 1 Predicted: 0\n",
      "ltable: ['13389', 'Pyrates', 'Comedy,Romance', '0', '49', '520', 'Noah Stern', '1992']\n",
      "rtable: ['5936', 'Pyrates', 'Comedy', '98', '60', '131', 'Noah Stern,', '1991']\n",
      "Label: 1 Predicted: 0\n",
      "\n",
      "RANDOM FOREST TEST\n",
      "Precision: 0.9795918367346939\n",
      "Recall: 0.9411764705882353\n",
      "F1: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Debug on only random forest\n",
    "clf = ensemble.RandomForestClassifier(verbose=True, min_samples_split=0.15, min_samples_leaf=3, n_estimators=200)\n",
    "train,test = setA[:225], setA[225:]\n",
    "feature, label = get_feature2(train)\n",
    "clf.fit(feature, label)\n",
    "path_x = clf.feature_importances_\n",
    "print(\"Random Forest weights\")\n",
    "# Result shows that weights are mostly place on \"Title\", \"Director\", \"Rating\", \"Duration\"\n",
    "# \"Title\" \"Category\" \"Rating\" \"Director\" \"Duration\" \"Rating Count\"\n",
    "print(path_x)\n",
    "precision, recall, F1 = clf_test(test, clf, \"Random Forest Test\", get_feature=get_feature2, verbose=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltable: ['7332', 'Wonder Woman', 'Short,Action,Fantasy', '3', '65', '1105', 'Sam Balcomb', '2013']\n",
      "rtable: ['8072', 'Wonder Woman', 'Action,Adventure,Science Fiction,Fantasy', 0, 50, '5555', 'Patty Jenkins,', '2017']\n",
      "Label: 0 Predicted: 1\n",
      "ltable: ['1037', 'Back to the Future Part II', 'Adventure,Comedy,Sci-Fi', '108', '78', '346518', 'Robert Zemeckis', '1989']\n",
      "rtable: ['3923', 'Back to the Future Part III', 'Action,Adventure,Comedy,Science Fiction,Fantasy', '119', '68', '693257', 'Robert Zemeckis,', '1990']\n",
      "Label: 0 Predicted: 1\n",
      "ltable: ['1666', 'The Phantom of the Opera', 'Horror', '93', '77', '12507', 'Rupert Julian,Lon Chaney', '1925']\n",
      "rtable: ['8865', 'Phantom Of The Opera', 'Classics,Drama,Horror', '79', '76', '17287', 'Rupert Julian,Edward Sedgwick,', '1925']\n",
      "Label: 1 Predicted: 0\n",
      "ltable: ['7334', 'Aquaman', 'Action,Adventure,Sci-Fi', '0', 50, 0, 'James Wan', '2018']\n",
      "rtable: ['18530', 'Aquaman', 'Action,Adventure,Drama,Science Fiction,Fantasy,Television', 0, '68', '433', 'Greg Beeman,', '2006']\n",
      "Label: 0 Predicted: 1\n",
      "\n",
      "FINAL CLASSIFIER EVALUATION(RANDOM FOREST)\n",
      "Precision: 0.9090909090909091\n",
      "Recall: 0.967741935483871\n",
      "F1: 0.9374999999999999\n"
     ]
    }
   ],
   "source": [
    "# Final Classifier\n",
    "clf = ensemble.RandomForestClassifier(min_samples_split=0.15, min_samples_leaf=3, n_estimators=200)\n",
    "feature, label = get_feature2(setA)\n",
    "clf = clf.fit(feature, label)\n",
    "precision, recall, F1 = clf_test(setB, clf, \"Final Classifier Evaluation(Random Forest)\", get_feature=get_feature2, verbose=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
